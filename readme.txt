curl -X POST "http://localhost:8000/crawl" -H "Content-Type: application/json" -d '{"url": "https://www.monicamariage.com", "max_pages": 3}'
curl -X POST localhost:8000/crawl -H "Content-Type: application/json" -d '{"url":"https://www.monicamariage.com","max_pages":1}'

uvicorn app:app --reload
Tu as raison ! Je vais te faire une documentation claire et compl√®te. Voici un **README.md** proper :

```markdown
# üîç SEO Audit Tool

Un outil d'audit SEO complet qui crawle et analyse automatiquement les sites web selon 30+ r√®gles SEO modernes (2025).

## ‚ú® Fonctionnalit√©s

- **Crawling automatique** : D√©couvre et analyse toutes les pages d'un site
- **Score SEO global** : Note de 0 √† 100 avec d√©tail par page
- **30+ r√®gles SEO** : Meta tags, structure HTML, accessibilit√©, performance, s√©curit√©
- **Recommandations d√©taill√©es** : Conseils pr√©cis pour am√©liorer le r√©f√©rencement
- **Support JavaScript** : Crawler Playwright en option pour les sites SPA
- **API REST** : Int√©gration facile dans d'autres outils

## üöÄ Installation & Lancement

### 1. Pr√©requis
```bash
# Python 3.8+ requis
pip install -r requirements.txt
```

### 2. Lancer l'API
```bash
# Lancement local
uvicorn app:app --reload

# L'API sera accessible sur : http://localhost:8000
```

### 3. Test rapide avec l'interface
Ouvre `test.html` dans ton navigateur, puis :
- Entre une URL (ex: `https://example.com`)
- Clique sur "Analyser"
- Regarde les r√©sultats !

## üì° Utilisation de l'API

### Endpoint principal : `POST /crawl`

**URL :** `http://localhost:8000/crawl`

**Param√®tres :**
```json
{
  "url": "https://example.com",     // URL √† analyser (obligatoire)
  "max_pages": 60,                 // Nombre max de pages (1-200, d√©faut: 60)
  "js": false                      // Utiliser Playwright pour le JS (d√©faut: false)
}
```

### Exemples d'utilisation

#### Curl basique (3 pages max)
```bash
curl -X POST localhost:8000/crawl \
  -H "Content-Type: application/json" \
  -d '{"url":"https://example.com","max_pages":3}'
```

#### Analyse compl√®te (60 pages)
```bash
curl -X POST localhost:8000/crawl \
  -H "Content-Type: application/json" \
  -d '{"url":"https://monsite.com","max_pages":60}'
```

#### Site avec JavaScript
```bash
curl -X POST localhost:8000/crawl \
  -H "Content-Type: application/json" \
  -d '{"url":"https://spa-site.com","max_pages":10,"js":true}'
```

#### Test de sant√© de l'API
```bash
curl http://localhost:8000/health
```

## üìä Format de r√©ponse

```json
{
  "pages": 3,
  "data": [
    {
      "url": "https://example.com/",
      "status": 200,
      "title": "Titre de la page",
      "score_global": 85,
      "score_legacy": 80,
      "score_rules": 5,
      "recommendations": [
        {
          "rule_id": "META_DESC_LENGTH",
          "topic": "Meta",
          "severity": "info",
          "message": "Meta description trop longue",
          "evidence": {"length": 180}
        }
      ],
      "meta_description": "...",
      "h1_count": 1,
      "images_without_alt": 0,
      "word_count": 450
    }
  ]
}
```

## üéØ R√®gles SEO analys√©es

### Meta & Structure
- ‚úÖ Title (50-60 caract√®res)
- ‚úÖ Meta description (150-160 caract√®res)
- ‚úÖ Canonical URL
- ‚úÖ Meta robots
- ‚úÖ Structure H1/H2

### Accessibilit√©
- ‚úÖ Images avec attribut alt
- ‚úÖ Meta viewport
- ‚úÖ Attribut lang sur `<html>`
- ‚úÖ Landmarks (main, nav, header, footer)

### Social & SEO moderne
- ‚úÖ Open Graph (og:title, og:image, og:url)
- ‚úÖ Twitter Cards
- ‚úÖ JSON-LD (schema.org)
- ‚úÖ Hreflang (multi-langues)

### Performance
- ‚úÖ Taille HTML (<400KB)
- ‚úÖ Lazy loading images
- ‚úÖ Formats modernes (WebP/AVIF)
- ‚úÖ Hints de performance (preload/preconnect)

### S√©curit√©
- ‚úÖ Headers de s√©curit√© (CSP, HSTS, X-Frame-Options...)

### AEO (AI Engine Optimization)
- ‚úÖ Fichiers `/ai.txt` et `/llms.txt` (tendance 2025)

## üîß Configuration avanc√©e

### Variables d'environnement
```bash
# Port personnalis√©
export PORT=3000
uvicorn app:app --host 0.0.0.0 --port $PORT
```

### Limite de pages par d√©faut
Modifie `max_pages` dans `app.py` ligne 23 :
```python
max_pages: Optional[int] = 60  # Change cette valeur
```

## üöÄ D√©ploiement

### Render.com (gratuit)
1. Fork ce repo sur GitHub
2. Connecte ton GitHub √† Render.com
3. Deploy avec `render.yaml` (d√©j√† configur√©)

### Docker
```dockerfile
FROM python:3.9-slim
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
RUN python -m playwright install chromium
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

## üìÅ Structure du projet

```
mon-outil-seo/
‚îú‚îÄ‚îÄ app.py                 # API FastAPI principale
‚îú‚îÄ‚îÄ seo_crawler.py         # Crawler BeautifulSoup
‚îú‚îÄ‚îÄ seo_crawler_js.py      # Crawler Playwright (JS)
‚îú‚îÄ‚îÄ seo_rules.py           # 30+ r√®gles SEO
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances Python
‚îú‚îÄ‚îÄ render.yaml           # Config d√©ploiement
‚îú‚îÄ‚îÄ test.html             # Interface de test
‚îî‚îÄ‚îÄ README.md             # Cette documentation
```

## üêõ Probl√®mes courants

### "Module not found"
```bash
pip install -r requirements.txt
```

### "Playwright not installed" (si js=true)
```bash
python -m playwright install chromium
```

### "Port already in use"
```bash
# Change le port
uvicorn app:app --port 8001
```

### Site bloqu√© par robots.txt
L'outil respecte le robots.txt. Si bloqu√©, le crawler s'arr√™te.

## üìà Exemples de scores

- **üü¢ 90-100** : Excellent SEO
- **üü° 70-89** : Bon, quelques am√©liorations
- **üü† 50-69** : Moyen, optimisations n√©cessaires  
- **üî¥ <50** : Probl√®mes SEO importants

## ü§ù Contribution

1. Fork le projet
2. Cr√©e une branche : `git checkout -b ma-feature`
3. Commit : `git commit -m 'Ajoute ma feature'`
4. Push : `git push origin ma-feature`
5. Ouvre une Pull Request

## üìÑ Licence

MIT License - Utilise librement !
```

Voil√† ! Une doc compl√®te avec :
- ‚úÖ Installation claire √©tape par √©tape
- ‚úÖ Exemples concrets de curl
- ‚úÖ Explication des param√®tres
- ‚úÖ Format de r√©ponse d√©taill√©
- ‚úÖ Liste compl√®te des r√®gles SEO
- ‚úÖ D√©ploiement et troubleshooting

Tu peux copier √ßa dans un `README.md` et ton projet sera beaucoup plus professionnel ! üöÄ