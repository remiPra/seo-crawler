# deepseek_analyzer.py
import os
import requests
from openai import OpenAI
from bs4 import BeautifulSoup
from typing import Dict, Any, Optional
import json
# deepseek_analyzer.py - Ajouter au d√©but (ligne 1-2)
from dotenv import load_dotenv
load_dotenv()  # Charge le fichier .env



def get_html_content(url: str) -> Optional[str]:
    """R√©cup√®re le HTML complet d'une page"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        print(f"‚úÖ HTML r√©cup√©r√© ({len(response.text):,} caract√®res)")
        return response.text
        
    except Exception as e:
        print(f"‚ùå Erreur r√©cup√©ration HTML : {e}")
        return None

def check_ai_files(base_url: str) -> Dict[str, Any]:
    """V√©rifie l'existence des fichiers IA (llms.txt, ai.txt, robots.txt)"""
    files_to_check = {
        'llms.txt': f"{base_url.rstrip('/')}/llms.txt",
        'ai.txt': f"{base_url.rstrip('/')}/ai.txt", 
        'robots.txt': f"{base_url.rstrip('/')}/robots.txt",
        'sitemap.xml': f"{base_url.rstrip('/')}/sitemap.xml"
    }
    
    results = {}
    
    for filename, file_url in files_to_check.items():
        try:
            response = requests.get(file_url, timeout=10)
            if response.status_code == 200:
                results[filename] = {
                    'exists': True,
                    'content_preview': response.text[:200] + "..." if len(response.text) > 200 else response.text
                }
                # Analyse sp√©ciale pour robots.txt
                if filename == 'robots.txt':
                    ai_bots = ['GPTBot', 'PerplexityBot', 'Claude-Web', 'Google-Extended', 'CCBot']
                    bot_status = {}
                    for bot in ai_bots:
                        if bot in response.text:
                            if f"Disallow: /" in response.text and bot in response.text:
                                bot_status[bot] = 'BLOQU√â'
                            else:
                                bot_status[bot] = 'AUTORIS√â'
                        else:
                            bot_status[bot] = 'NON MENTIONN√â'
                    results[filename]['ai_bots'] = bot_status
            else:
                results[filename] = {'exists': False, 'status_code': response.status_code}
        except Exception as e:
            results[filename] = {'exists': False, 'error': str(e)}
    
    return results

def analyze_with_deepseek(html_content: str, ai_files_check: Dict[str, Any], url: str) -> Optional[str]:
    """Analyse compl√®te d'optimisation IA avec DeepSeek V3"""
    
    # V√©rifier la cl√© API
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        raise Exception("DEEPSEEK_API_KEY non configur√©e dans les variables d'environnement")
    
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )
    
    # Parser le HTML pour analyse pr√©liminaire
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Extraire quelques infos cl√©s pour le prompt
    title = soup.find('title')
    title_text = title.get_text() if title else "Pas de titre"
    
    meta_desc = soup.find('meta', attrs={'name': 'description'})
    meta_desc_text = meta_desc.get('content') if meta_desc else "Pas de meta description"
    
    h1_tags = soup.find_all('h1')
    h1_count = len(h1_tags)
    h1_text = [h1.get_text().strip() for h1 in h1_tags]
    
    prompt = f"""
AUDIT SP√âCIALIS√â : OPTIMISATION POUR IA (Perplexity, ChatGPT, Claude, Gemini)
URL analys√©e : {url}

**DONN√âES PR√âLIMINAIRES :**
- Title: {title_text[:100]}...
- Meta description: {meta_desc_text[:100]}...  
- Nombre de H1: {h1_count}
- H1 trouv√©s: {h1_text}

**FICHIERS IA D√âTECT√âS :**
{json.dumps(ai_files_check, indent=2)}

**CHECKLIST COMPL√àTE √Ä AUDITER :**

üîç **SECTION 1: ACC√àS & FICHIERS IA**
- [ ] Pr√©sence /llms.txt √† la racine
- [ ] Pr√©sence /ai.txt (optionnel)  
- [ ] robots.txt autorise GPTBot, PerplexityBot, Claude-Web, Google-Extended
- [ ] Sitemaps complets & √† jour

üè∑Ô∏è **SECTION 2: M√âTADONN√âES IA SP√âCIFIQUES**
Rechercher dans le HTML ces balises sp√©ciales :
- [ ] <meta name="llm-friendly" content="true">
- [ ] <meta name="ai-content-declaration" content="human-generated">
- [ ] <meta name="content-summary" content="...">
- [ ] <meta name="key-points" content="...">
- [ ] <meta name="answer-engine-optimization" content="...">
- [ ] Balises <time datetime="..."> pour les dates

üìê **SECTION 3: STRUCTURATION CONTENU POUR IA**
- [ ] H1 unique = sujet clair (v√©rifier qu'il n'y en a qu'un)
- [ ] H2/H3 formul√©s en questions naturelles
- [ ] R√©ponse directe en premi√®re phrase des sections
- [ ] Paragraphes courts (2‚Äì4 phrases max)
- [ ] Listes √† puces ou num√©rot√©es pr√©sentes
- [ ] Pas de "cela/√ßa" ambigu ‚Üí r√©f√©rences claires
- [ ] Balises s√©mantiques : <strong>, <em>, <cite>, <abbr>, <dfn>, <blockquote>
- [ ] FAQ int√©gr√©e visible

üìä **SECTION 4: DONN√âES STRUCTUR√âES (Schema.org)**
D√©tecter dans le JSON-LD ou microdonn√©es :
- [ ] Organization / LocalBusiness avec NAP
- [ ] FAQPage pour Q/R
- [ ] HowTo pour tutoriels
- [ ] Article / BlogPosting (auteur, date, √©diteur)
- [ ] Product / Offer si e-commerce
- [ ] Dataset / DigitalDocument si applicable

üèÜ **SECTION 5: CR√âDIBILIT√â (E-E-A-T)**
- [ ] Auteur identifi√© + bio avec expertise
- [ ] Sources externes cit√©es avec liens
- [ ] Avis clients / t√©moignages visibles
- [ ] Page √Ä propos accessible
- [ ] Mentions l√©gales + Contact
- [ ] sameAs dans JSON-LD (r√©seaux sociaux)

üß™ **SECTION 6: OPTIMISATION MOTEURS DE R√âPONSE**
- [ ] Contenu adapt√© recherche vocale
- [ ] Snippets r√©utilisables (phrases percutantes)
- [ ] R√©ponses autonomes par section
- [ ] Maillage interne FAQ/guides
- [ ] Dates de mise √† jour visibles

**FORMAT DE R√âPONSE DEMAND√â :**

Pour chaque section, donne :
‚úÖ = Crit√®re respect√© (avec exemple du HTML)
‚ö†Ô∏è = Partiellement respect√© (avec d√©tails)
‚ùå = Non respect√© ou absent

**SCORE FINAL :**
- Score optimisation IA : X/100
- Top 3 des points forts pour les IA
- Top 5 des am√©liorations prioritaires pour √™tre mieux r√©f√©renc√© par Perplexity/ChatGPT/Claude

HTML √† analyser (extrait) :
{html_content[:20000]}
"""
    
    try:
        print("ü§ñ DeepSeek V3 analyse l'optimisation IA...")
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=5000
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse DeepSeek : {e}")
        raise Exception(f"Erreur DeepSeek API: {str(e)}")

def analyze_ai_optimization_complete(url: str) -> Dict[str, Any]:
    """Fonction principale d'analyse compl√®te"""
    try:
        # √âtape 1 : V√©rifier les fichiers IA
        base_url = '/'.join(url.split('/')[:3])  # https://domain.com
        ai_files_check = check_ai_files(base_url)
        
        # √âtape 2 : R√©cup√©rer le HTML
        html_content = get_html_content(url)
        
        if not html_content:
            return {
                "url": url,
                "error": "Impossible de r√©cup√©rer le HTML de la page",
                "success": False
            }
        
        # √âtape 3 : Analyse avec DeepSeek
        ai_report = analyze_with_deepseek(html_content, ai_files_check, url)
        
        return {
            "url": url,
            "success": True,
            "ai_files_check": ai_files_check,
            "html_size": len(html_content),
            "deepseek_analysis": ai_report,
            "model_used": "deepseek-chat",
            "analysis_type": "AI Optimization Audit"
        }
        
    except Exception as e:
        return {
            "url": url,
            "error": str(e),
            "success": False
        }